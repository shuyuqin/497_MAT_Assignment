{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import keras\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, LSTM, Dense\n",
    "from keras.models import Sequential, Input, Model\n",
    "from keras.layers import (Dense, Conv1D, Convolution2D, GRU, LSTM, Recurrent, Bidirectional, TimeDistributed,\n",
    "                          Dropout, Flatten, RepeatVector, Reshape, MaxPooling1D, UpSampling1D, BatchNormalization)\n",
    "from keras.layers.core import Lambda\n",
    "from keras.optimizers import Adam\n",
    "from keras.regularizers import l1\n",
    "from keras.models import load_model\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def function_gen(x, a, b, c, d, e, f, g):\n",
    "    y1 = a*(x-e)**3 + b*(x-f)**2+c*(x-g)+d\n",
    "    y2 = d*(x-g)**2 + c*x +a\n",
    "    return y1, y2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(0,1,100)\n",
    "\n",
    "y1 = []\n",
    "y2 = []\n",
    "a = []\n",
    "b = []\n",
    "c = []\n",
    "d = []\n",
    "e = np.random.uniform(0,10)\n",
    "f = np.random.uniform(0,10)\n",
    "g = np.random.uniform(0,10)\n",
    "for i in range(1000):\n",
    "\n",
    "    a_ = np.random.normal(8, 1.5, 1)\n",
    "    b_ = np.random.normal(2, 2, 1)\n",
    "    c_ = np.random.normal(4, 1, 1)\n",
    "    d_ = np.random.normal(0, 0.5, 1)\n",
    "\n",
    "    y1_, y2_ = function_gen(x, a_, b_, c_, d_, e, f, g)\n",
    "    \n",
    "    y1.append(y1_)\n",
    "    y2.append(y2_)\n",
    "    a.append(a_)\n",
    "    b.append(b_)\n",
    "    c.append(c_)\n",
    "    d.append(d_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "non-default argument follows default argument (<ipython-input-13-dfb353eb3ca4>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-13-dfb353eb3ca4>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    def rnn_auto(layer = 'lstm', size, num_encode_layers, num_decode_layers, embedding, n_step, lr = 3e-6, drop_frac=0.,bidirectional=False, l1_norm = 1e-4,**kwargs):\u001b[0m\n\u001b[0m                ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m non-default argument follows default argument\n"
     ]
    }
   ],
   "source": [
    "# def rnn_auto(layer , size, num_encode_layers, num_decode_layers, embedding, n_step, lr = 3e-6, drop_frac=0.,bidirectional=False, l1_norm = 1e-4,**kwargs):\n",
    "   \"\"\"\n",
    "    Function which builds the reccurrent neural network autoencoder\n",
    "    Parameters\n",
    "    ----------\n",
    "    layer : string; options: 'lstm','gru'\n",
    "        selects the layer type\n",
    "    size  : numpy, int\n",
    "        sets the size of encoding and decoding layers in the network\n",
    "    num_encode_layers  : numpy, int\n",
    "        sets the number of encoding layers in the network\n",
    "    num_decode_layers : numpy, int\n",
    "        sets the number of decoding layers in the network\n",
    "    embedding : numpy, int\n",
    "        sets the size of the embedding layer\n",
    "    n_steps : numpy, int\n",
    "        length of the input time series\n",
    "    lr : numpy, float\n",
    "        sets the learning rate for the model\n",
    "    drop_frac : numpy, float\n",
    "        sets the dropout fraction\n",
    "    bidirectional : numpy, bool\n",
    "        selects if the model is linear or bidirectional\n",
    "    l1_norm : numpy. float\n",
    "        sets the lambda value of the l1 normalization. The larger the value the greater the\n",
    "        sparsity. None can be passed to exclude the use or l1 normailzation.\n",
    "    Returns\n",
    "    -------\n",
    "    model : Keras, object\n",
    "        Keras tensorflow model\n",
    "    \"\"\"\n",
    "#     # defines the model\n",
    "#     model = Sequential()\n",
    "\n",
    "#     # selects if the model is bidirectional\n",
    "#     if bidirectional:\n",
    "#         wrapper = Bidirectional\n",
    "#         # builds the first layer\n",
    "#         model.add(Bidirectional(layer(size, return_sequences=(num_encode_layers > 1),  dropout=drop_frac),\n",
    "#                             input_shape=(n_step, 1)))\n",
    "#     else:\n",
    "#         wrapper = lambda x: x\n",
    "#         # builds the first layer\n",
    "#         model.add(wrapper(layer(size, return_sequences=(num_encode_layers > 1),  dropout=drop_frac,\n",
    "#                 input_shape=(n_step, 1))))\n",
    "\n",
    "#     # builds the encoding layers\n",
    "#     for i in range(1, num_encode_layers):\n",
    "#         model.add(wrapper(layer(size, return_sequences=(i < num_encode_layers - 1), dropout=drop_frac)))\n",
    "\n",
    "#     # builds the embedding layer\n",
    "#     if l1_norm == None:\n",
    "#         # embedding layer without l1 regulariization\n",
    "#         model.add(Dense(embedding, activation='relu', name='encoding'))\n",
    "#     else:\n",
    "#         # embedding layer with l1 regularization\n",
    "#         model.add(Dense(embedding, activation='relu', name='encoding',activity_regularizer=l1(l1_norm)))\n",
    "\n",
    "#     # builds the repeat vector\n",
    "#     model.add(RepeatVector(n_step))\n",
    "\n",
    "#     # builds the decoding layer\n",
    "#     for i in range(num_decode_layers):\n",
    "#         model.add(wrapper(layer(size, return_sequences=True, dropout=drop_frac)))\n",
    "\n",
    "#     # builds the time distributed layer to reconstruct the original input\n",
    "#     model.add(TimeDistributed(Dense(1, activation='linear')))\n",
    "\n",
    "#     # complies the model\n",
    "#     model.compile(Adam(lr), loss='mse')\n",
    "\n",
    "#     # returns the model\n",
    "#     return model\n",
    "\n",
    "# # def train_model(model, data_train, data_test, path, epochs, batch_size):\n",
    "\n",
    "# #     #builds the filename\n",
    "# #     filepath = path + '/weights.{epoch:02d}-{val_loss:.2f}.hdf5'\n",
    "# #     # sets the control of checkpoints\n",
    "# #     checkpoint = keras.callbacks.ModelCheckpoint(filepath, monitor='val_loss', verbose=0, save_best_only=True,\n",
    "# #                                              save_weights_only=True, mode='min', period=1)\n",
    "\n",
    "# #     # fits the model\n",
    "# #     model.fit(np.atleast_3d(data1), np.atleast_3d(data2), epochs=250000,\n",
    "# #           batch_size=1200, validation_data=(np.atleast_3d(data), np.atleast_3d(data)),\n",
    "# #           callbacks=[tbCallBack, checkpoint])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model( layer = LSTM, size = 8, num_encode_layers = 1 , num_decode_layers = 1, embedding = 16, n_step = 100, lr = 3e-6, drop_frac=0.,bidirectional=False, l1_norm = 1e-4, **kwargs):\n",
    "    model = Sequential()\n",
    "    if bidirectional:\n",
    "        wrapper = Bidirectional\n",
    "        # builds the first layer\n",
    "        model.add(Bidirectional(layer(size, return_sequences=(num_encode_layers > 1),  dropout=drop_frac),\n",
    "                            input_shape=(n_step, 1)))\n",
    "    else:\n",
    "        wrapper = lambda x: x\n",
    "        # builds the first layer\n",
    "        model.add(wrapper(layer(size, return_sequences=(num_encode_layers > 1),  dropout=drop_frac,\n",
    "                input_shape=(n_step, 1))))\n",
    "        \n",
    "    for i in range(1, num_encode_layers):\n",
    "        model.add(wrapper(layer(size, return_sequences=(i < num_encode_layers - 1), dropout=drop_frac)))\n",
    "\n",
    "    # builds the embedding layer\n",
    "    if l1_norm == None:\n",
    "        # embedding layer without l1 regulariization\n",
    "        model.add(Dense(embedding, activation='relu', name='encoding'))\n",
    "    else:\n",
    "        # embedding layer with l1 regularization\n",
    "        model.add(Dense(embedding, activation='relu', name='encoding',activity_regularizer=l1(l1_norm)))\n",
    "\n",
    "    # builds the repeat vector\n",
    "    model.add(RepeatVector(n_step))\n",
    "\n",
    "    # builds the decoding layer\n",
    "    for i in range(num_decode_layers):\n",
    "        model.add(wrapper(layer(size, return_sequences=True, dropout=drop_frac)))\n",
    "\n",
    "    # builds the time distributed layer to reconstruct the original input\n",
    "    model.add(TimeDistributed(Dense(1, activation='linear')))\n",
    "\n",
    "    # complies the model\n",
    "    model.compile(Adam(lr), loss='mse')\n",
    "\n",
    "    # returns the model\n",
    "    return model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KerasClassifier(build_fn = create_model, verbose = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "100/100 [==============================] - 2s 23ms/step - loss: 253.4781\n",
      "Epoch 2/100\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 253.4698\n",
      "Epoch 3/100\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 253.4607\n",
      "Epoch 4/100\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 253.4514\n",
      "Epoch 5/100\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 253.4429\n",
      "Epoch 6/100\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 253.4349\n",
      "Epoch 7/100\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 253.4257\n",
      "Epoch 8/100\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 253.4174\n",
      "Epoch 9/100\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 253.4086\n",
      "Epoch 10/100\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 253.4002\n",
      "Epoch 11/100\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 253.3914\n",
      "Epoch 12/100\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 253.3832\n",
      "Epoch 13/100\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 253.3744\n",
      "Epoch 14/100\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 253.3653\n",
      "Epoch 15/100\n",
      "100/100 [==============================] - 1s 9ms/step - loss: 253.3570\n",
      "Epoch 16/100\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 253.3484\n",
      "Epoch 17/100\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 253.3395\n",
      "Epoch 18/100\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 253.3312\n",
      "Epoch 19/100\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 253.3224\n",
      "Epoch 20/100\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 253.3136\n",
      "Epoch 21/100\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 253.3052\n",
      "Epoch 22/100\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 253.2963\n",
      "Epoch 23/100\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 253.2888\n",
      "Epoch 24/100\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 253.2792\n",
      "Epoch 25/100\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 253.2700\n",
      "Epoch 26/100\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 253.2619\n",
      "Epoch 27/100\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 253.2531\n",
      "Epoch 28/100\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 253.2442\n",
      "Epoch 29/100\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 253.2360\n",
      "Epoch 30/100\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 253.2266\n",
      "Epoch 31/100\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 253.2178\n",
      "Epoch 32/100\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 253.2081\n",
      "Epoch 33/100\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 253.2000\n",
      "Epoch 34/100\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 253.1902\n",
      "Epoch 35/100\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 253.1817\n",
      "Epoch 36/100\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 253.1724\n",
      "Epoch 37/100\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 253.1640\n",
      "Epoch 38/100\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 253.1553\n",
      "Epoch 39/100\n",
      "100/100 [==============================] - 1s 9ms/step - loss: 253.1467\n",
      "Epoch 40/100\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 253.1380\n",
      "Epoch 41/100\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 253.1297\n",
      "Epoch 42/100\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 253.1207\n",
      "Epoch 43/100\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 253.1121\n",
      "Epoch 44/100\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 253.1035\n",
      "Epoch 45/100\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 253.0947\n",
      "Epoch 46/100\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 253.0853\n",
      "Epoch 47/100\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 253.0767\n",
      "Epoch 48/100\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 253.0680\n",
      "Epoch 49/100\n",
      "100/100 [==============================] - 1s 9ms/step - loss: 253.0593\n",
      "Epoch 50/100\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 253.0513\n",
      "Epoch 51/100\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 253.0430\n",
      "Epoch 52/100\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 253.0348\n",
      "Epoch 53/100\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 253.0262\n",
      "Epoch 54/100\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 253.0172\n",
      "Epoch 55/100\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 253.0084\n",
      "Epoch 56/100\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 252.9995\n",
      "Epoch 57/100\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 252.9907\n",
      "Epoch 58/100\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 252.9825\n",
      "Epoch 59/100\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 252.9731\n",
      "Epoch 60/100\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 252.9649\n",
      "Epoch 61/100\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 252.9560\n",
      "Epoch 62/100\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 252.9475\n",
      "Epoch 63/100\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 252.9385\n",
      "Epoch 64/100\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 252.9300\n",
      "Epoch 65/100\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 252.9209\n",
      "Epoch 66/100\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 252.9119\n",
      "Epoch 67/100\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 252.9025\n",
      "Epoch 68/100\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 252.8940\n",
      "Epoch 69/100\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 252.8845\n",
      "Epoch 70/100\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 252.8753\n",
      "Epoch 71/100\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 252.8664\n",
      "Epoch 72/100\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 252.8581\n",
      "Epoch 73/100\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 252.8502\n",
      "Epoch 74/100\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 252.8420\n",
      "Epoch 75/100\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 252.8341\n",
      "Epoch 76/100\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 252.8257\n",
      "Epoch 77/100\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 252.8173\n",
      "Epoch 78/100\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 252.8085\n",
      "Epoch 79/100\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 252.8007\n",
      "Epoch 80/100\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 252.7919\n",
      "Epoch 81/100\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 252.7840\n",
      "Epoch 82/100\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 252.7757\n",
      "Epoch 83/100\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 252.7678\n",
      "Epoch 84/100\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 252.7602\n",
      "Epoch 85/100\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 252.7517\n",
      "Epoch 86/100\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 252.7429\n",
      "Epoch 87/100\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 252.7342\n",
      "Epoch 88/100\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 252.7257\n",
      "Epoch 89/100\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 252.7182\n",
      "Epoch 90/100\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 252.7094\n",
      "Epoch 91/100\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 252.7017\n",
      "Epoch 92/100\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 252.6930\n",
      "Epoch 93/100\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 252.6850\n",
      "Epoch 94/100\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 252.6755\n",
      "Epoch 95/100\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 252.6668\n",
      "Epoch 96/100\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 252.6583\n",
      "Epoch 97/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 1s 8ms/step - loss: 252.6492\n",
      "Epoch 98/100\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 252.6413\n",
      "Epoch 99/100\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 252.6324\n",
      "Epoch 100/100\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 252.6240\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1a7d680860>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Invalid shape for y: (1000, 100, 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-146-61c7f617a9be>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mgrid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_grid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparam_grid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mgrid_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0matleast_3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0matleast_3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m//anaconda3/lib/python3.7/site-packages/keras/wrappers/scikit_learn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, sample_weight, **kwargs)\u001b[0m\n\u001b[1;32m    203\u001b[0m             \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearchsorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 205\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Invalid shape for y: '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    206\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_classes_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Invalid shape for y: (1000, 100, 1)"
     ]
    }
   ],
   "source": [
    "num_encode_layers = [1,2,3,4]\n",
    "num_decode_layers = [1,2,3,4]\n",
    "embedding = [16,32]\n",
    "drop_frac = [0., 0.2, 0.5]\n",
    "epochs = [50,100,150]\n",
    "batch_size = [10,20,30]\n",
    "\n",
    "param_grid = dict( batch_size = batch_size, epochs = epochs)\n",
    "\n",
    "grid = GridSearchCV(estimator = model, param_grid = param_grid, n_jobs=-1, cv = 5)\n",
    "grid_result = model.fit(np.atleast_3d(y1), np.atleast_3d(y2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "             estimator=<keras.wrappers.scikit_learn.KerasClassifier object at 0x1aa2139d30>,\n",
       "             iid='warn', n_jobs=-1,\n",
       "             param_grid={'batch_size': [10, 20, 30], 'epochs': [50, 100, 150]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iList = [10,100,1000,10000,100000,1000000]\n",
    "x = np.linspace(0,1,100)\n",
    "netWork = [8,16,32,64,128,256,512]\n",
    "eCode = [1,2,3,4,5,10]\n",
    "dCode = [1,2,3,4,5,10]\n",
    "eBed = [16,32]\n",
    "loss = 999999999\n",
    "f_y1 = []\n",
    "f_y2 = []\n",
    "f_fit = []\n",
    "information = []\n",
    "for i in iList:\n",
    "    y1 = []\n",
    "    y2 = []\n",
    "    a = []\n",
    "    b = []\n",
    "    c = []\n",
    "    d = []\n",
    "    e = []\n",
    "    f = []\n",
    "    z1 = np.random.uniform(0,12)\n",
    "    z2 = np.random.uniform(0,12)\n",
    "    z3 = np.random.uniform(0,12)\n",
    "    z4 = np.random.uniform(0,12)\n",
    "    z5 = np.random.uniform(0,12)\n",
    "    z6 = np.random.uniform(0,12)\n",
    "    z7 = np.random.uniform(0,12)\n",
    "    z8 = np.random.uniform(0,12)\n",
    "    z9 = np.random.uniform(0,12)\n",
    "    z10 = np.random.uniform(0,12)\n",
    "    z11 = np.random.uniform(0,12)\n",
    "    z12 = np.random.uniform(0,12)\n",
    "    \n",
    "    for k in range(i):\n",
    "        a_ = np.random.normal(8, 1, 1)\n",
    "        b_ = np.random.normal(7, 2, 1)\n",
    "        c_ = np.random.normal(6, 3, 1)\n",
    "        d_ = np.random.normal(5, 4, 1)\n",
    "        e_ = np.random.normal(4, 5, 1)\n",
    "        f_ = np.random.normal(3, 7, 1)\n",
    "        y1_, y2_ = function_gen(x, a_, b_, c_, d_,e_,f_,z1,z2,z3,z4,z5,z6,z7,z8,z9,z10,z11,z12)\n",
    "        y1.append(y1_)\n",
    "        y2.append(y2_)\n",
    "        a.append(a_)\n",
    "        b.append(b_)\n",
    "        c.append(c_)\n",
    "        d.append(d_)\n",
    "        e.append(e_)\n",
    "        f.append(f_)\n",
    "        \n",
    "    nor_y1 = preprocessing.normalize(y1)\n",
    "    nor_y2 = preprocessing.normalize(y2)\n",
    "        \n",
    "    for j in netWork:\n",
    "        for l in eCode:\n",
    "            for m in dCode:\n",
    "                for n in eBed:\n",
    "                    auto_test = rnn_auto(LSTM, j, l, m, n, 100)\n",
    "                    model1 = auto_test.fit(np.atleast_3d(nor_y1), np.atleast_3d(nor_y2), epochs= 200, batch_size=2000)\n",
    "                    if model1.history['loss'][199] < loss:\n",
    "                        loss = model1.history['loss'][199]\n",
    "                        auto_test.save('auto_test')\n",
    "                        nor_y1_result = auto_test.predict(np.atleast_3d(nor_y1))\n",
    "                        f_y1 = nor_y1\n",
    "                        f_y2 = nor_y2\n",
    "                        f_fit = nor_y1_result\n",
    "                        information = [i,j,l,m,n]\n",
    "                    \n",
    "               \n",
    "            \n",
    "           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ -974.74832884,  -968.96365556,  -963.20139351, ...,\n",
       "         -511.12253491,  -507.29514552,  -503.48565476],\n",
       "       [ -757.92186893,  -753.47032716,  -749.03541071, ...,\n",
       "         -398.25284342,  -395.24731657,  -392.25494334],\n",
       "       [-1265.73934135, -1258.2713742 , -1250.832189  , ...,\n",
       "         -666.52033953,  -661.56522354,  -656.63307706],\n",
       "       ...,\n",
       "       [-1171.56853534, -1164.58197964, -1157.62386916, ...,\n",
       "         -618.07397483,  -613.5864069 ,  -609.12186337],\n",
       "       [-1078.40058881, -1072.00929965, -1065.64306967, ...,\n",
       "         -567.56395097,  -563.36475678,  -559.18565001],\n",
       "       [-1114.10504419, -1107.54061698, -1101.00196086, ...,\n",
       "         -589.6120028 ,  -585.30314573,  -581.0149717 ]])"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y3 = np.asarray(y1)\n",
    "y3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 100)"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y4.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 9.88307848,  9.89663999,  9.91021985, ..., 11.28400275,\n",
       "        11.29934464, 11.31470488],\n",
       "       [13.16712736, 13.17226121, 13.17745246, ..., 13.9323492 ,\n",
       "        13.94305051, 13.95380922],\n",
       "       [-1.09281647, -1.00171322, -0.91069384, ...,  7.35368362,\n",
       "         7.43665114,  7.51953478],\n",
       "       ...,\n",
       "       [ 1.97558044,  2.03040755,  2.08517973, ...,  7.03806168,\n",
       "         7.0875607 ,  7.13700479],\n",
       "       [14.39124829, 14.40124265, 14.41128448, ..., 15.5817021 ,\n",
       "        15.59630064, 15.61094665],\n",
       "       [13.43125123, 13.46707389, 13.50293504, ..., 17.08526165,\n",
       "        17.1248179 , 17.16441265]])"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y4 = np.asarray(y2)\n",
    "y4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "y5 = y4[ : , 0 : 1] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 1)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y5.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "y6 = y5.reshape(-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 9.88307848e+00,  1.31671274e+01, -1.09281647e+00,  2.23376005e+01,\n",
       "        2.07947232e+01,  6.92468847e+00,  2.16828645e+01, -1.23678426e+01,\n",
       "        6.08171952e+00, -3.72872134e+00,  1.36797086e+01,  2.59041811e+01,\n",
       "        1.81903663e+01, -7.78974547e+00,  1.25691637e+01, -6.22730523e-01,\n",
       "        2.11721207e+01,  1.43507350e+01,  1.86320777e+01,  1.29664250e+01,\n",
       "        3.10908208e+00,  8.97524815e-01,  1.13538175e+01, -6.72410486e+00,\n",
       "        2.48916924e+01,  9.04400283e+00,  3.82424683e+00,  2.34127721e+00,\n",
       "        1.72900459e+01, -7.10684554e-01,  1.03339400e+00,  8.43162647e+00,\n",
       "        9.71195983e+00,  2.34076021e+01,  1.54065523e+01,  8.78100424e+00,\n",
       "       -1.20442543e+00, -2.05050362e+00, -2.73527497e+01,  1.97758017e+01,\n",
       "        1.73271820e+01,  1.88597609e+01, -1.95137121e+00,  4.56546366e+00,\n",
       "        1.41726612e+01,  2.79133652e+01,  8.67247252e+00,  2.12674499e+01,\n",
       "       -4.56854088e+00,  1.61102822e+01,  2.62972666e+01,  1.28982241e+01,\n",
       "       -8.59048259e+00,  3.47867883e+01, -4.87660354e+00,  2.85286382e+01,\n",
       "        1.78731414e+01, -1.65326800e+01,  1.94073214e+00,  1.55807290e+01,\n",
       "        1.22764607e+01,  3.57833840e+01,  2.78126315e+01,  2.75015992e+01,\n",
       "        1.80713897e+01, -6.58441390e+00, -1.30593337e+01, -1.16858921e+01,\n",
       "        6.36075386e+00,  9.08498815e+00,  1.53119374e+01,  2.66209338e+01,\n",
       "        8.06606556e+00,  2.27008611e+01,  2.76808884e+01,  1.06350318e+01,\n",
       "       -4.00361649e+00, -3.98501740e+00,  3.60759761e-01, -6.22637121e+00,\n",
       "        3.81845861e+00,  1.37192385e+01,  1.30216494e+01,  1.69571154e+01,\n",
       "        1.46926190e+01, -4.51984472e+00,  5.29871402e+00,  2.60660248e+01,\n",
       "        1.29034296e+01, -6.67010076e+00,  8.45228125e+00, -1.35855848e+01,\n",
       "       -1.23291648e+01,  1.03601800e+01,  7.56037539e-01,  3.83036432e+00,\n",
       "        1.28739298e+01,  1.60984076e+01,  2.51326851e+00,  1.27091246e+00,\n",
       "       -3.00230176e-01, -1.96396987e+01,  2.15023677e+01,  6.98038581e+00,\n",
       "       -9.19188418e+00,  1.66251677e+01,  1.66943808e+01,  2.42847499e+01,\n",
       "        2.11639408e+01, -3.15340164e+00,  1.40168086e+01,  2.00249834e+01,\n",
       "        2.37470911e+01,  5.47156020e+00,  1.21015321e+01, -1.14339745e+01,\n",
       "        1.21601922e+00,  2.09051148e+01,  2.66138251e+01,  5.37595763e+00,\n",
       "       -8.30033548e+00,  5.47896812e+00,  1.75733533e+01,  1.01425034e+01,\n",
       "        1.30659225e+01, -1.80238032e+01,  1.04679279e+01,  6.61872041e+00,\n",
       "        3.25287999e+00,  1.74711326e+01,  4.15285678e+00,  1.76937431e+01,\n",
       "        6.85151577e+00,  1.60922251e+01,  3.55983359e+01, -1.33747090e+00,\n",
       "       -8.24286028e-01,  9.70600145e+00,  1.43549772e+01,  1.46904136e+01,\n",
       "        1.97603566e+01,  2.59973838e+01,  5.15568396e+00, -1.13088569e+00,\n",
       "       -1.96501992e+00,  2.77686487e+01,  1.52469902e+01, -8.60555867e+00,\n",
       "        2.62221260e+01,  2.55402197e+01, -2.04138469e+01,  3.16426650e+01,\n",
       "        1.59545755e+01,  1.47729325e+01, -6.10145673e+00,  9.66299816e+00,\n",
       "        1.49281732e+01,  7.77732516e+00,  5.46114624e+00,  4.07173710e+00,\n",
       "        4.16718498e+01,  1.25499081e+01,  2.05684426e+01,  1.02748021e+01,\n",
       "        2.33833929e+01,  1.24210186e+01, -7.81823490e+00,  9.25037219e-01,\n",
       "        8.67816708e+00, -6.25814395e+00,  4.76449995e+00,  2.36429246e+01,\n",
       "       -5.28672548e+00, -3.80652853e+00,  9.63777414e+00,  1.38753429e+01,\n",
       "        1.44687924e+01,  2.26465398e+01,  2.02513031e+01,  8.17148618e+00,\n",
       "        2.90629152e+01,  4.07622324e+01,  2.31805738e+01,  5.91486957e+00,\n",
       "        5.79058554e+00, -9.67510616e+00,  1.77295768e+01,  1.90359022e+01,\n",
       "       -5.19287784e+00,  3.52599487e+01, -6.97626263e+00,  1.56709148e+01,\n",
       "       -1.08138747e+01, -7.22808467e+00,  3.85343561e+01,  1.50791406e+01,\n",
       "        1.01669556e+01, -1.13891737e+01,  1.48723367e+01,  8.10178561e-01,\n",
       "       -1.80399547e+01,  2.38819267e+00,  4.68762620e+00, -1.18982019e+00,\n",
       "        9.51099090e+00,  1.12614890e+01, -2.95554099e+00,  1.51653424e+01,\n",
       "        1.11627346e+00,  4.95935947e+00,  1.12666609e+00,  6.93613036e+00,\n",
       "       -9.59605680e+00, -2.28802444e+00,  3.16170389e+00,  2.74960696e+01,\n",
       "        1.05979729e+01, -6.08632787e+00,  3.15602199e+01,  1.17077015e+01,\n",
       "        1.95114643e+01,  1.10204467e+01,  2.33634364e+01,  1.19017915e+01,\n",
       "        2.91032050e+00,  2.07388360e+01, -9.80803916e+00, -1.81812301e+01,\n",
       "        1.28225044e+01,  1.11283334e+01, -3.60135387e+00, -2.19468697e+00,\n",
       "       -4.72604515e+00,  1.87769032e+01,  3.98350347e+00,  2.41024402e+01,\n",
       "        8.54393473e+00, -2.36433044e+00,  3.05584055e+01,  1.89636868e+01,\n",
       "        1.89915035e+01,  1.41288189e+01,  1.66312138e+01,  2.19444710e+01,\n",
       "        7.44129498e+00,  8.64771877e+00, -7.93822740e-01, -9.08684745e+00,\n",
       "        2.36015635e+01, -8.02512824e-02,  1.11165352e+01, -2.01043313e+00,\n",
       "       -1.85848793e+00,  4.45605814e+00, -1.56688173e-01,  4.00016339e+00,\n",
       "        1.57634966e+01,  1.82374487e+01, -7.32129989e-01,  2.36435272e+01,\n",
       "        1.87452868e+00,  1.06732200e+01,  1.94881135e+01,  3.23269503e+01,\n",
       "        2.14199414e+01, -4.58670732e+00, -7.40827986e+00, -3.34438130e+00,\n",
       "       -8.88954873e+00, -1.26738369e+01,  2.47229258e+01, -1.99770288e+01,\n",
       "        3.88493714e+01, -7.07320186e+00, -1.64432707e+00,  1.01069427e+01,\n",
       "       -2.20820493e+01,  1.32958059e+01,  8.59248925e-01,  2.75163641e+01,\n",
       "        2.85822430e+01,  4.51446025e+00, -1.26383648e+00,  8.26041720e+00,\n",
       "        2.76316575e+01,  1.65980251e+01,  2.14397428e+01,  1.98852681e+00,\n",
       "        1.31312727e+01,  7.04454487e+00,  2.55040593e+01,  3.37411300e+01,\n",
       "        1.52408288e+00,  2.64780390e+01,  3.80782942e+01,  1.32817942e+01,\n",
       "       -7.22869168e+00,  1.32416456e+01,  2.00528510e+01,  9.64930499e+00,\n",
       "        7.24675397e+00,  1.21596415e+01, -7.00253824e+00,  3.09015562e+01,\n",
       "        1.57042376e+00,  6.04588836e+00,  1.01289460e+01,  2.79992188e+01,\n",
       "       -1.44043474e+01, -4.25836229e+00,  1.17668098e+01,  9.71046479e+00,\n",
       "        6.80345312e+00,  1.66218808e+01,  1.36919737e+01, -1.21609441e+01,\n",
       "        1.33268766e+01,  4.03684497e+00,  1.42750968e+01,  8.53893662e+00,\n",
       "        6.87158446e+00,  2.61606543e+01, -1.00454808e+01, -9.69910096e+00,\n",
       "        1.63347720e+01,  2.87207648e+01,  2.18674875e+01,  1.50076402e+01,\n",
       "        1.08850473e+01,  3.32383784e+00, -3.26655309e+00,  1.80732597e+01,\n",
       "        1.68553123e+01,  3.82654568e+00,  2.61936749e+01,  1.61068046e+01,\n",
       "       -4.85091352e+00,  2.21148744e+00,  2.42246337e+01,  1.08635068e+01,\n",
       "        1.52941912e+01,  1.30081385e+01,  8.43910684e+00, -3.27817435e+00,\n",
       "       -1.34486058e+01,  5.29275107e+00,  1.28727329e+01, -9.66508174e+00,\n",
       "       -7.45298173e-02,  1.29558881e+01, -1.51259118e+00, -1.22226815e+01,\n",
       "       -1.68565824e+01,  1.16147785e+01,  5.33742506e+00,  1.13100445e+00,\n",
       "        2.61136463e+00, -3.87698714e+00,  1.82105883e+01,  2.19498369e+01,\n",
       "        5.10425039e+00, -1.36124372e+00,  5.34590003e+00,  2.82428298e+01,\n",
       "        2.59035774e+01,  6.51354155e+00,  1.59978679e+01, -6.10203195e+00,\n",
       "        3.06853726e+01,  4.10039811e+00,  5.86023987e+00,  3.06267706e+01,\n",
       "        5.21668566e+00,  1.11251029e+01,  1.48811533e+01, -1.19136652e+01,\n",
       "        2.35371307e+00, -1.77827460e+01, -7.05582993e+00,  2.77063928e+01,\n",
       "        5.84991069e-01,  1.98497099e+01,  4.71629131e+00, -3.36720246e+00,\n",
       "        1.24237551e+01,  1.71073360e+01, -1.22749564e+00,  1.29080694e+01,\n",
       "        5.76889045e+00,  2.38815447e+01,  1.95769184e+01,  8.00585579e+00,\n",
       "        2.53641896e+01,  9.23943645e+00,  1.51092655e+01, -2.33726256e-01,\n",
       "       -2.13440961e+01,  9.07309160e+00,  1.09396226e+01,  8.78429187e-01,\n",
       "       -5.00636978e+00,  2.40059010e+01, -2.37987250e+00,  4.89383100e+00,\n",
       "       -6.40943600e+00,  8.41145777e+00,  6.70007983e+00,  1.64727148e+01,\n",
       "       -1.63610870e+00,  2.69453991e+00,  3.52385107e+01, -1.75198364e+01,\n",
       "        1.10068988e+01,  6.94298655e+00,  1.97034709e+01,  8.42101294e+00,\n",
       "       -6.99193886e+00,  2.34046596e+01,  2.05707497e+01,  5.60868519e+00,\n",
       "        3.59693685e+01,  1.68061871e+01, -4.14602703e+00,  2.04198151e+01,\n",
       "        4.81295378e-01,  2.16371891e+00,  1.97099006e+01,  5.06825480e-01,\n",
       "        3.04061871e+01, -9.61441555e-01,  7.39761152e+00,  2.15612983e+01,\n",
       "        3.28025905e+01,  1.66651992e+01,  1.04820945e+01,  2.75532197e+00,\n",
       "        2.15353331e+01, -1.60689760e+01, -2.50938342e+00, -2.97768844e+00,\n",
       "        1.63976508e+01,  8.45086366e+00, -2.56757830e+00,  1.46561976e+01,\n",
       "       -9.44276220e+00, -5.18370741e+00,  3.02350945e+01,  3.62512375e+00,\n",
       "        2.09528535e+01,  1.44107217e+01,  6.42117448e+00, -4.59880391e+00,\n",
       "        4.73360976e+00,  1.54944543e+01,  1.59657425e+01, -1.56495659e+00,\n",
       "        7.59377836e+00,  2.17201268e+01,  1.52354509e+01,  3.23760605e+00,\n",
       "       -8.56110144e+00,  2.38198673e+01,  2.09732849e+01, -4.47029542e+00,\n",
       "       -7.14139771e+00,  2.92307679e+00,  9.66634651e+00,  1.16287754e+01,\n",
       "        3.36256779e+00,  1.68587511e+01,  1.30875004e+01,  4.91000397e-01,\n",
       "       -1.30079821e+01,  8.52038882e+00, -1.41719317e+01,  8.42669024e+00,\n",
       "        2.94737411e+01,  1.32790721e+01,  1.95687939e+01, -3.81743485e+00,\n",
       "       -2.08752251e+00,  1.90205907e+00, -9.44585566e+00,  1.92997620e+01,\n",
       "        2.87678417e+01,  3.34840370e+01,  1.56651225e+01, -6.08997903e+00,\n",
       "       -1.09196659e+00,  1.38990458e+01,  1.11459892e+01,  2.11911427e+01,\n",
       "       -1.30251210e+01,  1.98627951e+00,  2.86953786e+01,  1.47301708e+01,\n",
       "        1.93542875e+01,  1.90695648e+01,  7.05407444e+00, -3.18888458e+00,\n",
       "       -4.47084575e+00,  1.85088262e+01,  1.03005674e+01,  2.53876281e+01,\n",
       "        1.07988311e+01,  9.69757621e-02,  4.16855386e+01,  2.64125986e+01,\n",
       "       -2.02958434e+01, -3.94051826e+00,  8.58876681e+00, -1.66283298e+00,\n",
       "       -7.83916088e-01, -2.42534612e+01,  6.03885442e+00, -2.70711902e+00,\n",
       "       -8.80246299e-01,  3.95140435e+00,  7.07215773e+00,  1.72268893e+01,\n",
       "       -4.34510048e+00,  1.83854552e+01,  2.73650273e+00, -2.75716375e+00,\n",
       "        2.67008602e+01,  3.26236210e+00,  1.20247505e+01,  7.43352005e+00,\n",
       "        1.48793104e+00,  1.38046608e+01,  2.87383733e+01,  1.07116301e+01,\n",
       "        3.99973073e+01,  2.19678971e+01,  2.16706328e+01,  1.36807414e+01,\n",
       "       -1.33663983e+01,  5.41460882e+00,  1.70505257e+01,  1.19411051e+01,\n",
       "        3.83479051e-01,  1.12287494e+01,  2.07108016e+01,  1.94187243e+01,\n",
       "        1.94441674e+01, -1.42247720e+00,  7.32850749e+00,  1.26262060e+01,\n",
       "       -1.07324121e+01,  1.93313278e+01, -5.90815237e+00,  6.89552574e+00,\n",
       "        7.04874283e-01, -9.07674652e+00,  9.76298993e+00, -1.12881092e+00,\n",
       "       -1.48646808e+00,  7.65565514e+00,  3.54764145e+01,  2.08208698e+00,\n",
       "        1.94660890e+01,  1.38571130e+01,  9.06293203e+00,  2.57743621e+01,\n",
       "        1.15805356e+01,  2.70436967e+01,  1.34750524e+01,  2.00135304e+01,\n",
       "        7.66394640e+00,  1.17710898e+01, -9.88251686e-01, -4.23621014e+00,\n",
       "        2.40634231e+00, -4.51953191e-01, -1.10333643e+01,  1.79631157e+00,\n",
       "       -7.93051039e+00, -2.06309191e+00, -1.04601534e+01,  1.03607470e+01,\n",
       "        1.13264757e+01,  1.16148864e+01,  8.63318231e+00,  1.13605663e+01,\n",
       "       -2.21944914e+00,  1.80220378e+01,  1.28859638e+01, -1.49546154e+00,\n",
       "        2.32338581e+01,  2.12267301e+01,  8.15283371e+00,  3.97226615e+00,\n",
       "       -1.35427003e-01,  4.57481758e+00,  7.47881472e+00, -6.62119290e-01,\n",
       "       -1.33630894e+00,  2.09045330e+01,  9.80252159e+00,  4.14014322e+00,\n",
       "        5.70666078e+00,  1.70367831e+00,  5.88458026e+00, -4.47523722e+00,\n",
       "        2.15474343e+01, -1.99088354e+00, -8.40700206e+00,  8.74530909e+00,\n",
       "        2.27726339e+01,  5.78983574e+00,  2.58057451e+00,  2.01490541e+01,\n",
       "        1.30209010e+01,  4.59990818e+00, -9.14984796e+00,  7.84379002e+00,\n",
       "        1.42777398e+01, -8.87343730e+00, -9.73538192e+00, -1.37866857e+01,\n",
       "       -5.90649499e+00,  1.60587428e+01,  6.16648650e+00,  1.79111073e+01,\n",
       "        9.46558272e+00,  1.43352002e-01, -2.93902187e+00,  2.30877325e+01,\n",
       "        1.43710715e+01,  1.19514397e+01, -4.34290185e+00,  2.01336717e+01,\n",
       "        1.87932640e+01,  2.24273093e+01,  3.50429322e+01, -5.56232004e+00,\n",
       "        3.55575283e+00,  1.49854539e+01,  9.25407191e-01, -3.47030530e+01,\n",
       "        1.73394603e+01,  2.06719378e+01,  1.61796578e+01,  1.00298724e+01,\n",
       "       -5.93792601e+00,  1.65171109e+01, -1.24673442e+00,  1.97080007e+01,\n",
       "        1.89757099e+01,  1.00287357e+01,  2.53060720e+01,  1.40447776e+01,\n",
       "        9.18290913e+00,  8.71055657e+00, -6.42334293e+00,  2.68432937e+01,\n",
       "        1.07446550e+01, -2.13146371e+01,  8.02431499e+00,  4.39442341e+01,\n",
       "       -3.50324994e+00,  1.76717180e+01,  7.65079400e+00,  1.01053191e+01,\n",
       "        5.18024798e-01,  1.75555925e+01, -4.59245277e-01,  1.52475660e+01,\n",
       "        6.80745620e+00,  6.11991556e-01,  1.43339087e+01,  1.02580382e+01,\n",
       "        3.56694236e+00,  2.30039430e+01, -3.42683986e+00,  1.68955528e+01,\n",
       "        8.71525011e+00,  1.89829815e+01,  3.02885017e+00,  1.07858441e+01,\n",
       "        6.21354650e+00, -7.06334146e+00, -1.06204409e+00,  2.38498331e+01,\n",
       "       -2.54032394e+00,  8.08382578e+00,  9.26673309e+00,  2.58300795e+01,\n",
       "        1.11270322e+01, -6.99495865e+00,  6.21904852e+00, -2.17386904e+00,\n",
       "        7.49985140e+00,  5.13598175e+00,  3.36886713e+00, -1.34225639e+01,\n",
       "        8.71633700e+00,  2.35715831e+01,  1.04585151e+01,  5.31539518e+00,\n",
       "        6.98649478e+00,  1.22870509e+01,  1.04312692e+01,  1.73119067e+01,\n",
       "        1.00988008e+01, -7.43587203e+00,  6.50155112e-01, -9.21182670e+00,\n",
       "       -5.23300487e-01,  2.31166628e+01,  2.35191664e+01, -3.45650125e-01,\n",
       "        1.88921193e+01, -5.44151486e+00, -5.41778171e+00, -1.17716982e+01,\n",
       "        6.75759297e+00, -1.19907306e+00,  1.02754983e+01, -1.28170770e+01,\n",
       "        2.57394232e+01,  1.79731224e+01,  1.45825037e+01, -5.28465468e+00,\n",
       "        1.52138995e+01, -4.01074314e+00,  2.67118207e+01, -2.23361165e+00,\n",
       "       -4.71365571e+00,  6.66311468e+00,  1.69532861e+01,  3.25351129e+00,\n",
       "        1.08470515e+00, -9.10673484e+00,  1.50510677e+01,  8.60162309e-01,\n",
       "        3.22882933e+00,  1.17273145e+00,  1.47570610e+01,  2.89917413e+01,\n",
       "       -2.48430765e+00, -2.56842788e+00,  6.42131661e-01,  9.93684191e+00,\n",
       "        5.36178818e+00,  1.82251169e+01,  1.39249968e+01,  1.93147331e+01,\n",
       "        3.96116685e+00,  5.10637915e+00,  1.15102948e+01,  2.19706599e+01,\n",
       "        1.50665483e+01,  3.16420946e+01,  1.00409738e+01, -6.04885495e+00,\n",
       "        5.74338290e+00, -2.57686240e+00,  1.02201219e+01,  4.97821447e+00,\n",
       "        1.98073888e+01, -5.68745697e+00, -8.66824265e+00,  5.96430954e+00,\n",
       "        1.84755366e+01,  3.43806990e+01,  3.15986349e+00, -6.44623089e-01,\n",
       "        2.11370351e+01,  4.45637216e+00, -1.02362214e+01, -1.38961770e+01,\n",
       "        1.86833325e+00,  2.94749798e+01,  3.26128495e+00,  9.99451349e+00,\n",
       "       -1.99293420e-02,  1.68445267e+00,  1.59250820e+01, -5.91452907e+00,\n",
       "       -1.67244419e+01, -6.35084124e+00,  9.28926724e+00,  1.55120595e+01,\n",
       "       -1.41117009e+01,  2.66728129e+01,  2.10913233e+00,  1.96652795e+01,\n",
       "       -1.14139992e+01, -8.51805568e+00,  1.85246069e+01, -1.03795059e-01,\n",
       "        1.09090637e+01,  2.72049061e+01, -1.60026234e+01,  2.06979565e+01,\n",
       "       -2.54965423e+00,  1.21512939e+01, -4.89543216e+00, -3.32136662e+00,\n",
       "        4.99941917e+00,  1.14048116e+01,  3.22660899e+00, -5.69648434e+00,\n",
       "        2.66473760e+01, -5.22343555e+00,  3.16075133e+01,  3.20498844e+01,\n",
       "        4.08901295e+00, -2.21000314e+00,  6.90524137e+00,  8.27426732e+00,\n",
       "        1.28173937e+01, -2.87556402e+00,  3.33802004e+01,  1.22877342e+01,\n",
       "        1.19727957e+01, -2.67238533e+01, -1.31815674e+01, -1.86551354e+01,\n",
       "        1.59706031e+01, -4.98453941e+00,  2.16165143e+00, -1.74916905e+01,\n",
       "        2.68851392e+01,  1.19082706e+01,  3.07230061e+01, -5.50452732e+00,\n",
       "        1.59514038e+01, -9.75840557e+00,  8.65919751e+00, -8.71481317e+00,\n",
       "        1.22937132e+01,  2.10990978e+00,  2.09173160e-01, -2.57804241e-02,\n",
       "        1.94678207e+01,  3.06328916e+00,  2.95484020e+01,  1.98182448e+01,\n",
       "        1.10325122e+01,  1.50955294e+01,  2.10602652e+00,  7.56625582e+00,\n",
       "        1.32474122e+01, -6.82859872e+00, -1.74330217e+01,  6.24112207e-01,\n",
       "        7.03247960e+00,  2.15796828e+01,  3.03585507e+01,  1.20018899e+01,\n",
       "        1.41485996e+01, -5.50545003e+00,  1.13816005e+01, -2.45164049e+00,\n",
       "        8.91499546e+00,  1.17036433e+01,  3.27766925e+00,  5.45993926e+00,\n",
       "        1.89634286e+01, -7.60507465e+00, -4.19271434e+00,  1.87567039e+01,\n",
       "       -9.66634270e+00,  3.73904494e+00,  2.86011367e+00,  1.73041360e+01,\n",
       "        3.87148447e+01, -1.27895893e+01,  1.08660416e+01,  1.88510293e+01,\n",
       "       -1.07651861e+01,  2.66783235e+01,  8.30234907e+00, -1.84832105e+01,\n",
       "       -1.06634713e+01,  1.42193726e+01,  1.63425334e+01,  2.01797837e+01,\n",
       "        1.14412304e+01, -6.88161310e+00,  6.61695437e+00,  8.49397998e+00,\n",
       "        1.06856400e+01, -3.21348664e+00, -2.07105429e+01,  1.60654980e+01,\n",
       "        2.21100667e+00,  1.09153555e+01,  4.68997362e+00,  1.00929831e+01,\n",
       "        1.06154729e+01, -8.41999182e+00,  7.42553274e+00,  8.61942504e+00,\n",
       "       -2.73721915e+00, -2.43736616e+01,  5.62500229e+00,  1.92950065e+01,\n",
       "       -2.50489753e+00, -1.30625360e+01,  7.59772953e+00,  9.96432429e+00,\n",
       "       -3.39358839e+00,  8.02086234e+00, -3.51067156e+00,  2.32789735e+01,\n",
       "        6.27792224e+00,  1.22132013e+01,  2.37129346e+01,  2.97568987e+01,\n",
       "        2.02922337e+01, -4.42030186e+00,  1.25320690e+01, -2.68502926e+00,\n",
       "        4.17028669e+00, -1.54263099e+01, -1.20805830e+01,  4.19509962e+01,\n",
       "        7.12354237e+00, -3.95751750e+00, -9.89529823e+00,  1.15510554e+01,\n",
       "        9.49610960e+00,  2.10075681e+01, -3.29836532e+00,  1.25160946e+00,\n",
       "        2.23832506e+01, -1.09022651e+01,  2.09648109e+00, -4.94934423e+00,\n",
       "       -9.30816698e+00,  2.16533982e+01,  4.22439219e+01,  1.68344111e+01,\n",
       "        8.92075314e+00, -5.20900070e+00, -2.43226999e+00, -1.13933678e+01,\n",
       "        5.99600508e+00,  1.22045654e+01,  1.88561229e+01,  2.89569959e+00,\n",
       "       -6.11006508e-02,  8.02061653e+00, -2.05252075e-01, -1.17186013e+01,\n",
       "        4.72422457e+01, -4.08075407e+00, -8.17453179e+00,  5.31831392e+00,\n",
       "        1.26058278e+01,  1.42504178e+01,  1.85268387e+00,  3.11596729e+01,\n",
       "        2.51748369e+01,  1.09113407e+01,  5.08403353e+00, -3.19543223e+00,\n",
       "        1.09029121e+01,  3.24820335e+01,  1.27620035e+01, -1.08526592e+00,\n",
       "        5.64549081e+00,  3.39857086e-01,  2.85226549e+01,  2.34442473e+01,\n",
       "        1.77309633e+01,  1.21052111e+01,  7.15640169e+00,  5.55879489e+00,\n",
       "        1.14225155e+01,  8.80155987e+00, -2.18047510e+00, -1.13767719e+01,\n",
       "       -4.34848263e+00,  1.09228638e+01, -1.00380249e+01,  1.67190291e+01,\n",
       "        1.45978140e+01, -2.57985026e+00,  1.16581498e+01,  1.19687085e+01,\n",
       "        1.60002479e+01, -2.75510809e+00,  6.10293094e+00,  1.88468685e+01,\n",
       "        2.40725838e+01,  5.91756501e+00, -1.59331746e+00,  8.73113561e+00,\n",
       "       -1.73305749e-01,  2.71257432e+01, -6.35505606e+00,  5.39950746e+00,\n",
       "        3.08001665e+01,  1.97558044e+00,  1.43912483e+01,  1.34312512e+01])"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'KerasClassifier' object has no attribute 'summary'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-148-5f15418b3570>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'KerasClassifier' object has no attribute 'summary'"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
