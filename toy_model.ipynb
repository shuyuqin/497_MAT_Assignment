{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(K.tensorflow_backend._get_available_gpus())\n",
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "#\n",
    "import tensorflow as tf\n",
    "#import keras.backend.tensorflow_backend as KTF\n",
    "gpu_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "for device in gpu_devices:\n",
    "    tf.config.experimental.set_memory_growth(device,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/device:CPU:0', '/device:XLA_CPU:0', '/device:XLA_GPU:0', '/device:XLA_GPU:1']\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "def get_available_devices():\n",
    "    local_device_protos = device_lib.list_local_devices()\n",
    "    return [x.name for x in local_device_protos]\n",
    "\n",
    "print(get_available_devices())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow.keras.layers as layers\n",
    "import tensorflow.keras\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, LSTM, Dense\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import (Attention,MaxPool1D,Dense, Conv1D, Convolution2D, GRU, LSTM, Bidirectional, TimeDistributed,\n",
    "                          Dropout, Flatten, LayerNormalization,RepeatVector, Reshape, MaxPooling1D, UpSampling1D, BatchNormalization)\n",
    "from tensorflow.keras.layers import Layer\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.regularizers import l1, l2\n",
    "from tensorflow.keras.models import load_model\n",
    "from sklearn import preprocessing\n",
    "from tensorflow.keras.models import load_model\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn import linear_model\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import random\n",
    "#from keras import layers as layers\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from scipy import special\n",
    "import torchvision.datasets as dsets\n",
    "import torchvision.transforms as transforms\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "#from keras_self_attention import SeqSelfAttention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import mnist\n",
    "import numpy as np\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.astype('float32') / 255.\n",
    "x_test = x_test.astype('float32') / 255.\n",
    "x_train = x_train.reshape((len(x_train), np.prod(x_train.shape[1:])))\n",
    "x_test = x_test.reshape((len(x_test), np.prod(x_test.shape[1:])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_identity_block(n_step=784,lr = 3e-4, drop_frac=0, l1_norm  = 0):\n",
    "    \n",
    "    X_input = layers.Input(shape=(n_step,1))\n",
    "    X = X_input\n",
    "    X = layers.Dense(24,activation='relu',name= 'encoder_dense')(X)\n",
    "   # X = layers.add([X, X_shortcut])\n",
    "    X = layers.BatchNormalization(axis=1)(X)\n",
    "    X = layers.Activation('relu')(X) \n",
    "    model = Model(inputs=X_input, outputs=X, name='ResNet50')\n",
    "    model.compile(Adam(lr), loss='mse')\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoderlayer = encode_identity_block()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"ResNet50\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         [(None, 784, 1)]          0         \n",
      "_________________________________________________________________\n",
      "encoder_dense (Dense)        (None, 784, 24)           48        \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 784, 24)           3136      \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 784, 24)           0         \n",
      "=================================================================\n",
      "Total params: 3,184\n",
      "Trainable params: 1,616\n",
      "Non-trainable params: 1,568\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "encoderlayer.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_8 (InputLayer)         [(None, 784)]             0         \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 128)               100480    \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dense_28 (Dense)             (None, 64)                1088      \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 128)               8320      \n",
      "_________________________________________________________________\n",
      "dense_30 (Dense)             (None, 784)               101136    \n",
      "=================================================================\n",
      "Total params: 221,888\n",
      "Trainable params: 221,888\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnimplementedError",
     "evalue": " The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW\n\t [[node model_20/conv1d_75/conv1d (defined at <ipython-input-125-da0ef010bc0d>:4) ]] [Op:__inference_distributed_function_98452]\n\nFunction call stack:\ndistributed_function\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnimplementedError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-125-da0ef010bc0d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m intermediate_layer_model = Model(inputs=autoencoder.input,\n\u001b[1;32m      3\u001b[0m                                  outputs=autoencoder.get_layer(layer_name).output)\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mintermediate_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mintermediate_layer_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test_3d\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1011\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1012\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1013\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m   1014\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1015\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, model, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    496\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPREDICT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    497\u001b[0m         \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 498\u001b[0;31m         workers=workers, use_multiprocessing=use_multiprocessing, **kwargs)\n\u001b[0m\u001b[1;32m    499\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    500\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36m_model_iteration\u001b[0;34m(self, model, mode, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    473\u001b[0m               \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m               \u001b[0mtraining_context\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 475\u001b[0;31m               total_epochs=1)\n\u001b[0m\u001b[1;32m    476\u001b[0m           \u001b[0mcbks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[0;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[1;32m    126\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[1;32m    127\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[0;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[0;34m(input_fn)\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[0;32m---> 98\u001b[0;31m                               distributed_function(input_fn))\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    566\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    567\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 568\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    569\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    570\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    636\u001b[0m               *args, **kwds)\n\u001b[1;32m    637\u001b[0m       \u001b[0;31m# If we did not create any variables the trace we have is good enough.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 638\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_concrete_stateful_fn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcanon_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcanon_kwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    639\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    640\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfn_with_cond\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minner_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0minner_kwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1609\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1610\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1611\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1612\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1613\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1690\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1691\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1692\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1693\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1694\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    543\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"executor_type\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"config_proto\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 545\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m     \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m     keras_symbolic_tensors = [\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "\u001b[0;31mUnimplementedError\u001b[0m:  The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW\n\t [[node model_20/conv1d_75/conv1d (defined at <ipython-input-125-da0ef010bc0d>:4) ]] [Op:__inference_distributed_function_98452]\n\nFunction call stack:\ndistributed_function\n"
     ]
    }
   ],
   "source": [
    "layer_name = 'dense_56'\n",
    "intermediate_layer_model = Model(inputs=autoencoder.input,\n",
    "                                 outputs=autoencoder.get_layer(layer_name).output)\n",
    "intermediate_output = intermediate_layer_model.predict(x_test_3d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 128)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intermediate_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 16)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autoencoder.get_layer('dense_27').get_weights()[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'list' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-43-5b0620a1f81c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mautoencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'dense_27'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: 'list' object is not callable"
     ]
    }
   ],
   "source": [
    "autoencoder.layers('dense_27')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_img = Input(shape=(784,))\n",
    "encoded = Dense(128, activation='relu')(input_img)\n",
    "encoded = Dense(64, activation='relu')(encoded)\n",
    "encoded = Dense(32, activation='relu')(encoded)\n",
    "\n",
    "\n",
    "embedding = Dense(16, activation='relu',activity_regularizer=l1(1e-4))(encoded)\n",
    "\n",
    "decoded = Dense(64, activation='relu')(embedding)\n",
    "decoded = Dense(128, activation='relu')(decoded)\n",
    "decoded = Dense(784, activation='relu')(decoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder = Model(input_img, decoded)\n",
    "autoencoder.compile(optimizer='adam', loss='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      "60000/60000 [==============================] - 2s 36us/sample - loss: 0.0536 - val_loss: 0.0371\n",
      "Epoch 2/50\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0327 - val_loss: 0.0292\n",
      "Epoch 3/50\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0277 - val_loss: 0.0260\n",
      "Epoch 4/50\n",
      "60000/60000 [==============================] - 1s 20us/sample - loss: 0.0254 - val_loss: 0.0242\n",
      "Epoch 5/50\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0241 - val_loss: 0.0234\n",
      "Epoch 6/50\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0233 - val_loss: 0.0229\n",
      "Epoch 7/50\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0227 - val_loss: 0.0222\n",
      "Epoch 8/50\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0222 - val_loss: 0.0217\n",
      "Epoch 9/50\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0218 - val_loss: 0.0214\n",
      "Epoch 10/50\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0214 - val_loss: 0.0211\n",
      "Epoch 11/50\n",
      "60000/60000 [==============================] - 1s 20us/sample - loss: 0.0212 - val_loss: 0.0207\n",
      "Epoch 12/50\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0206 - val_loss: 0.0204\n",
      "Epoch 13/50\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0204 - val_loss: 0.0202\n",
      "Epoch 14/50\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0202 - val_loss: 0.0199\n",
      "Epoch 15/50\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0200 - val_loss: 0.0199\n",
      "Epoch 16/50\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0198 - val_loss: 0.0196\n",
      "Epoch 17/50\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0196 - val_loss: 0.0194\n",
      "Epoch 18/50\n",
      "60000/60000 [==============================] - 2s 30us/sample - loss: 0.0194 - val_loss: 0.0193\n",
      "Epoch 19/50\n",
      "60000/60000 [==============================] - 1s 18us/sample - loss: 0.0192 - val_loss: 0.0191\n",
      "Epoch 20/50\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0191 - val_loss: 0.0188\n",
      "Epoch 21/50\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0189 - val_loss: 0.0189\n",
      "Epoch 22/50\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0188 - val_loss: 0.0188\n",
      "Epoch 23/50\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0187 - val_loss: 0.0186\n",
      "Epoch 24/50\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0186 - val_loss: 0.0186\n",
      "Epoch 25/50\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0185 - val_loss: 0.0187\n",
      "Epoch 26/50\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0184 - val_loss: 0.0184\n",
      "Epoch 27/50\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0183 - val_loss: 0.0183\n",
      "Epoch 28/50\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0183 - val_loss: 0.0185\n",
      "Epoch 29/50\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0182 - val_loss: 0.0182\n",
      "Epoch 30/50\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0181 - val_loss: 0.0182\n",
      "Epoch 31/50\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0180 - val_loss: 0.0181\n",
      "Epoch 32/50\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0179 - val_loss: 0.0181\n",
      "Epoch 33/50\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0179 - val_loss: 0.0179\n",
      "Epoch 34/50\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0178 - val_loss: 0.0179\n",
      "Epoch 35/50\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0178 - val_loss: 0.0179\n",
      "Epoch 36/50\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0177 - val_loss: 0.0177\n",
      "Epoch 37/50\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0176 - val_loss: 0.0176\n",
      "Epoch 38/50\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0175 - val_loss: 0.0175\n",
      "Epoch 39/50\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0174 - val_loss: 0.0176\n",
      "Epoch 40/50\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0173 - val_loss: 0.0174\n",
      "Epoch 41/50\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0172 - val_loss: 0.0173\n",
      "Epoch 42/50\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0172 - val_loss: 0.0172\n",
      "Epoch 43/50\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0171 - val_loss: 0.0171\n",
      "Epoch 44/50\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0170 - val_loss: 0.0171\n",
      "Epoch 45/50\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0169 - val_loss: 0.0170\n",
      "Epoch 46/50\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0169 - val_loss: 0.0170\n",
      "Epoch 47/50\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0169 - val_loss: 0.0169\n",
      "Epoch 48/50\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0168 - val_loss: 0.0171\n",
      "Epoch 49/50\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0168 - val_loss: 0.0169\n",
      "Epoch 50/50\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0167 - val_loss: 0.0168\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fadec43e510>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autoencoder.fit(x_train, x_train,\n",
    "                epochs=50,\n",
    "                batch_size=256,\n",
    "                shuffle=True,\n",
    "                validation_data=(x_test, x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoded_imgs = autoencoder.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x288 with 20 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# use Matplotlib (don't ask)\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "n = 10  # how many digits we will display\n",
    "plt.figure(figsize=(20, 4))\n",
    "for i in range(n):\n",
    "    # display original\n",
    "    ax = plt.subplot(2, n, i + 1)\n",
    "    plt.imshow(x_test[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "\n",
    "    # display reconstruction\n",
    "    ax = plt.subplot(2, n, i + 1 + n)\n",
    "    plt.imshow(decoded_imgs[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x288 with 20 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "n = 10  # how many digits we will display\n",
    "plt.figure(figsize=(20, 4))\n",
    "for i in range(n):\n",
    "    # display original\n",
    "    ax = plt.subplot(2, n, i + 1)\n",
    "    plt.imshow(x_test[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "\n",
    "    # display reconstruction\n",
    "    ax = plt.subplot(2, n, i + 1 + n)\n",
    "    plt.imshow(decoded_imgs[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_img = Input(shape=(784,1))\n",
    "encoded = Dense(256, activation='relu')(input_img)\n",
    "encoded = Conv1D(128, kernel_size = 2, strides=2, activation='relu',data_format='channels_first')(encoded)\n",
    "encoded = Conv1D(64, kernel_size = 2,strides=2, activation='relu',data_format='channels_first')(encoded)\n",
    "encoded = Conv1D(32, kernel_size = 2,strides=2, activation='relu',data_format='channels_first')(encoded)\n",
    "\n",
    "encoded = Bidirectional(LSTM(16, return_sequences=False,\n",
    "                             activity_regularizer=l1(1e-4)))(encoded)\n",
    "\n",
    "\n",
    "embedding = Dense(16, activation='relu',activity_regularizer=l1(1e-4))(encoded)\n",
    "repeat = RepeatVector(64)(embedding)\n",
    "\n",
    "decoded = Conv1D(64, kernel_size = 2,strides=2, activation='relu',data_format='channels_first')(repeat)\n",
    "decoded = Conv1D(128, kernel_size = 2,strides=2, activation='relu',data_format='channels_first')(decoded)\n",
    "decoded = Conv1D(784, kernel_size = 2,strides=2, activation='relu',data_format='channels_first')(decoded)\n",
    "decoded = Conv1D(784, kernel_size = 2,strides=2, activation='relu',data_format='channels_first')(decoded)\n",
    "\n",
    "decoded = Dense(1,activation='linear')(decoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder = Model(input_img, decoded)\n",
    "autoencoder.compile(optimizer='adam', loss='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_5 (InputLayer)         [(None, 784, 1)]          0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 784, 256)          512       \n",
      "_________________________________________________________________\n",
      "conv1d_19 (Conv1D)           (None, 128, 128)          200832    \n",
      "_________________________________________________________________\n",
      "conv1d_20 (Conv1D)           (None, 64, 64)            16448     \n",
      "_________________________________________________________________\n",
      "conv1d_21 (Conv1D)           (None, 32, 32)            4128      \n",
      "_________________________________________________________________\n",
      "bidirectional_4 (Bidirection (None, 32)                6272      \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "repeat_vector_1 (RepeatVecto (None, 64, 16)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_22 (Conv1D)           (None, 64, 8)             8256      \n",
      "_________________________________________________________________\n",
      "conv1d_23 (Conv1D)           (None, 128, 4)            16512     \n",
      "_________________________________________________________________\n",
      "conv1d_24 (Conv1D)           (None, 784, 2)            201488    \n",
      "_________________________________________________________________\n",
      "conv1d_25 (Conv1D)           (None, 784, 1)            1230096   \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 784, 1)            2         \n",
      "=================================================================\n",
      "Total params: 1,685,074\n",
      "Trainable params: 1,685,074\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 784)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_3d = np.atleast_3d(x_train)\n",
    "x_test_3d = np.atleast_3d(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 784, 1)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_3d.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      "  256/60000 [..............................] - ETA: 4:08"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": " Conv2DCustomBackpropFilterOp only supports NHWC.\n\t [[node Conv2DBackpropFilter (defined at <ipython-input-12-f6f066380807>:5) ]] [Op:__inference_distributed_function_2050]\n\nFunction call stack:\ndistributed_function\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-f6f066380807>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m                 \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                 \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m                 validation_data=(x_test_3d, x_test_3d))\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    817\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 819\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    340\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m                 \u001b[0mtraining_context\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 342\u001b[0;31m                 total_epochs=epochs)\n\u001b[0m\u001b[1;32m    343\u001b[0m             \u001b[0mcbks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[0;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[1;32m    126\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[1;32m    127\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[0;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[0;34m(input_fn)\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[0;32m---> 98\u001b[0;31m                               distributed_function(input_fn))\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    566\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    567\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 568\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    569\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    570\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    630\u001b[0m         \u001b[0;31m# Lifting succeeded, so variables are initialized and we can run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    631\u001b[0m         \u001b[0;31m# stateless function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 632\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    633\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    634\u001b[0m       \u001b[0mcanon_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcanon_kwds\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2361\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2362\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2363\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2365\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1609\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1610\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1611\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1612\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1613\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1690\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1691\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1692\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1693\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1694\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    543\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"executor_type\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"config_proto\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 545\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m     \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m     keras_symbolic_tensors = [\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m:  Conv2DCustomBackpropFilterOp only supports NHWC.\n\t [[node Conv2DBackpropFilter (defined at <ipython-input-12-f6f066380807>:5) ]] [Op:__inference_distributed_function_2050]\n\nFunction call stack:\ndistributed_function\n"
     ]
    }
   ],
   "source": [
    "autoencoder.fit(x_train_3d, x_train_3d,\n",
    "                epochs=50,\n",
    "                batch_size=256,\n",
    "                shuffle=True,\n",
    "                validation_data=(x_test_3d, x_test_3d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoded_imgs = autoencoder.predict(x_test_3d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use Matplotlib (don't ask)\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "n = 10  # how many digits we will display\n",
    "plt.figure(figsize=(20, 4))\n",
    "for i in range(n):\n",
    "    # display original\n",
    "    ax = plt.subplot(2, n, i + 1)\n",
    "    plt.imshow(x_test_3d[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "\n",
    "    # display reconstruction\n",
    "    ax = plt.subplot(2, n, i + 1 + n)\n",
    "    plt.imshow(decoded_imgs[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
