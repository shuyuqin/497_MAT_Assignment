{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(K.tensorflow_backend._get_available_gpus())\n",
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "#\n",
    "import tensorflow as tf\n",
    "#import keras.backend.tensorflow_backend as KTF\n",
    "gpu_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "for device in gpu_devices:\n",
    "    tf.config.experimental.set_memory_growth(device,True)\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  # Restrict TensorFlow to only use the first GPU\n",
    "  try:\n",
    "    tf.config.experimental.set_visible_devices(gpus[1], 'GPU')\n",
    "    logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPU\")\n",
    "  except RuntimeError as e:\n",
    "    # Visible devices must be set before GPUs have been initialized\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow.keras.layers as layers\n",
    "import tensorflow.keras\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, LSTM, Dense\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import (Attention,Dense, Conv1D, Convolution2D, GRU, LSTM, Bidirectional, TimeDistributed,\n",
    "                          Dropout, Flatten, LayerNormalization,RepeatVector, Reshape, MaxPooling1D, UpSampling1D, BatchNormalization)\n",
    "from tensorflow.keras.layers import Layer\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.regularizers import l1, l2\n",
    "from tensorflow.keras.models import load_model\n",
    "from sklearn import preprocessing\n",
    "from tensorflow.keras.models import load_model\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn import linear_model\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import random\n",
    "#from keras import layers as layers\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from scipy import special\n",
    "import torchvision.datasets as dsets\n",
    "import torchvision.transforms as transforms\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "#from keras_self_attention import SeqSelfAttention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from sklearn.decomposition import NMF\n",
    "from scipy import io\n",
    "import numpy as np\n",
    "import os\n",
    "import os.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_identity_block(X, stage, block, size, n_step, drop_frac, l2_norm):\n",
    "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
    "    bn_name_base = 'enconde' + str(stage) + block + '_branch'\n",
    "    \n",
    "    X_shortcut = X\n",
    "    X = Attention()([X,X_shortcut])\n",
    "    X = layers.Bidirectional(LSTM(size, return_sequences=True, dropout=drop_frac,\n",
    "                                  activity_regularizer=l1(l2_norm)),input_shape=(n_step, 1))(X)\n",
    "    \n",
    "   # X = layers.BatchNormalization(axis = 1, name = bn_name_base + '2a')(X)\n",
    "    X = layers.Activation('relu')(X)\n",
    "    \n",
    "    X = layers.Bidirectional(LSTM(size, return_sequences=True, dropout=drop_frac,\n",
    "                                  activity_regularizer=l1(l2_norm)),input_shape=(n_step, 1))(X)\n",
    "    \n",
    "   # X = layers.BatchNormalization(axis = 1, name = bn_name_base + '2b')(X)\n",
    "    X = layers.Activation('relu')(X)\n",
    "    \n",
    "    X = layers.Bidirectional(LSTM(size, return_sequences=True, dropout=drop_frac,\n",
    "                                  activity_regularizer=l1(l2_norm)),input_shape=(n_step, 1))(X)\n",
    "    \n",
    "   # X = layers.BatchNormalization(axis = 1, name = bn_name_base + '2c')(X)\n",
    "    \n",
    "    X = layers.add([X, X_shortcut])\n",
    "    X = LayerNormalization(axis=1 , center=True , scale=True)(X)\n",
    "    X = layers.Activation('relu')(X)\n",
    "    \n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_identity_block(X, stage, block, size, n_step, drop_frac, l2_norm):\n",
    "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
    "    bn_name_base = 'decode' + str(stage) + block + '_branch'\n",
    "    \n",
    "    X_shortcut = X\n",
    "    X = layers.Bidirectional(LSTM(size, return_sequences=True, dropout=drop_frac, \n",
    "                                  activity_regularizer=l1(l2_norm)))(X)\n",
    "    #X = layers.BatchNormalization(axis = 1, name = bn_name_base + '2a')(X)\n",
    "    X = layers.Activation('relu')(X)\n",
    "    \n",
    "    X = layers.Bidirectional(LSTM(size, return_sequences=True, dropout=drop_frac, \n",
    "                             activity_regularizer=l1(l2_norm)))(X)\n",
    "    \n",
    "    #X = layers.BatchNormalization(axis = 1, name = bn_name_base + '2b')(X)\n",
    "    X = layers.Activation('relu')(X)\n",
    "    \n",
    "    X = layers.Bidirectional(LSTM(size, return_sequences=True, dropout=drop_frac, \n",
    "                             activity_regularizer=l1(l2_norm)))(X)\n",
    "    #X = layers.BatchNormalization(axis = 1, name = bn_name_base + '2c')(X)\n",
    "    \n",
    "    X = layers.add([X, X_shortcut])\n",
    "    X = LayerNormalization(axis=1 , center=True , scale=True)(X)\n",
    "    X = layers.Activation('relu')(X)\n",
    "    \n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ResNet50(lr=3e-5, size=128, drop_frac=0, n_step=96, embedding = 16, l1_norm = 1e-5):\n",
    "\n",
    "    X_input = layers.Input(shape=(n_step,1))\n",
    "    X = X_input\n",
    "\n",
    "    X = encode_identity_block(X, 2, 'b', size, n_step, drop_frac, l1_norm)\n",
    "    X = encode_identity_block(X, 2, 'c', size, n_step, drop_frac, l1_norm)\n",
    "    X = encode_identity_block(X, 2, 'd', size, n_step, drop_frac, l1_norm)\n",
    "\n",
    "    X = layers.Bidirectional(LSTM(size, return_sequences=False, dropout=drop_frac,\n",
    "                             activity_regularizer=l1(l1_norm)),input_shape=(n_step, 1))(X)\n",
    "    #X = layers.BatchNormalization(axis=1, name='last_encode')(X)\n",
    "    X = layers.Activation('relu')(X)\n",
    "    X = layers.Dense(embedding,activation='relu',name='embedding_layer',activity_regularizer=l1(l1_norm))(X)\n",
    "    X = layers.RepeatVector(n_step)(X)\n",
    "    \n",
    "    X = layers.Bidirectional(LSTM(size, return_sequences=True, dropout=drop_frac, \n",
    "                             activity_regularizer=l1(l1_norm)))(X)\n",
    "    \n",
    "    #X = layers.BatchNormalization(axis = 1, name = 'fires_decode')(X)\n",
    "    X = layers.Activation('relu')(X)\n",
    "\n",
    "    X = decode_identity_block(X, 2, 'b', size, n_step, drop_frac, l1_norm)\n",
    "    X = decode_identity_block(X, 2, 'c', size, n_step, drop_frac, l1_norm)\n",
    "    X = decode_identity_block(X, 2, 'd', size, n_step, drop_frac, l1_norm)\n",
    "    \n",
    "    X = layers.BatchNormalization(axis = 1, name = 'batch_normal')(X)\n",
    "    X = layers.TimeDistributed(Dense(1, activation='linear'))(X)\n",
    "    model = Model(inputs=X_input, outputs=X, name='ResNet50')\n",
    "    model.compile(Adam(lr), loss='mse')\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "Try = ResNet50()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
