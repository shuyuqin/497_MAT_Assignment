{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow.keras.layers as layers\n",
    "import tensorflow.keras\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, LSTM, Dense\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import (Attention,Dense, Conv1D, Convolution2D, GRU, LSTM, Bidirectional, TimeDistributed,\n",
    "                          Dropout, Flatten, LayerNormalization,RepeatVector, Reshape, MaxPooling1D, UpSampling1D, BatchNormalization)\n",
    "from tensorflow.keras.layers import Layer\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.regularizers import l1, l2\n",
    "from tensorflow.keras.models import load_model\n",
    "from sklearn import preprocessing\n",
    "from tensorflow.keras.models import load_model\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn import linear_model\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import random\n",
    "#from keras import layers as layers\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from scipy import special\n",
    "import torchvision.datasets as dsets\n",
    "import torchvision.transforms as transforms\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "#from keras_self_attention import SeqSelfAttention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from sklearn.decomposition import NMF\n",
    "from scipy import io\n",
    "import numpy as np\n",
    "import os\n",
    "import os.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def s_1(b1, b2, Vbot, C1, D1):\n",
    "    s1 = (b1+b2)/2 + ((b2-b1)/2)*special.erfc((Vbot-C1)/D1)\n",
    "    return s1\n",
    "    \n",
    "def s_2(b3, b4, Vbot, C2, D2):\n",
    "    s2 = (b3+b4)/2 + ((b4-b3)/2)*special.erfc((Vbot-C2)/D2)\n",
    "    return s2\n",
    "\n",
    "def s_3(b5, b6, Vbot, C3, D3):\n",
    "    s3 = (b5+b6)/2 + ((b6-b5)/2)*special.erfc((Vbot-C3)/D3)\n",
    "    return s3\n",
    "\n",
    "def s_4(b7, b8, Vtop, C4, D4):\n",
    "    s4 = (b7+b8)/2 + ((b8-b7)/2)*special.erfc((Vtop-C4)/D4)\n",
    "    return s4\n",
    "\n",
    "def s_5(b9, b10, Vtop, C5, D5):\n",
    "    s5 = (b9+b10)/2 + ((b10-b9)/2)*special.erfc((Vtop-C5)/D5)\n",
    "    return s5\n",
    "\n",
    "def s_6(b11, b12, Vtop, C6, D6):\n",
    "    s6 = (b11+b12)/2 + ((b12-b11)/2)*special.erfc((Vtop-C6)/D6)\n",
    "    return s6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def F_1(a1, a2, a3, a4, a7,Al1, Al2, Al3, s1, s2, s3, Vbot,x,y):\n",
    "    F1 = a1+(a1-a2)*(special.erfc((Vbot+Al1)/s1)+1)/2 + x*(a2-a3)*(special.erfc((Vbot+Al2)/s2)+1)/2 + y*(a3-a4)*(special.erfc((Vbot+Al3)/s3)+1)/2 + a7*Vtop\n",
    "    return F1\n",
    "\n",
    "def F_2(a1, a5, a6, a4, a7, Au1, Au2, Au3, s4, s5, s6, Vtop,x,y):\n",
    "    F2 = a1+(a1-a5)*(special.erfc((Vtop+Au1)/s4)+1)/2 + x*(a5-a6)*(special.erfc((Vtop+Au2)/s5)+1)/2 + y*(a6-a4)*(special.erfc((Vtop+Au3)/s6)+1)/2 + a7*Vtop\n",
    "    return F2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Vbot = np.linspace(-15,15,96)\n",
    "Vtop = np.linspace(-15,15,96)\n",
    "a1 = -5\n",
    "a2 = 3\n",
    "a3 = 12\n",
    "a4 = 15\n",
    "a5 = 2\n",
    "a6 = 10\n",
    "a7 = 0.01\n",
    "b1 = 1\n",
    "b2 = 5\n",
    "b3 = 1\n",
    "b4 = 5\n",
    "b5 = 1\n",
    "b6 = 4\n",
    "b7 = 1\n",
    "b8 = 4\n",
    "b9 = 1\n",
    "b10= 4\n",
    "b11= 1\n",
    "b12= 4\n",
    "Al1= 3\n",
    "Al2= -2\n",
    "Al3= -6\n",
    "Au1= -8\n",
    "Au2= -4\n",
    "Au3= 0\n",
    "C1 = -1\n",
    "C2 = -1\n",
    "C3 = -1\n",
    "C4 = 6\n",
    "C5 = 6\n",
    "C6 = 6\n",
    "D1 = 1\n",
    "D2 = 1\n",
    "D3 = 1\n",
    "D4 = 1\n",
    "D5 = 1\n",
    "D6 = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1 = s_1(b1, b2, Vbot, C1, D1)\n",
    "s2 = s_2(b3, b4, Vbot, C2, D2)\n",
    "s3 = s_3(b5, b6, Vbot, C3, D3)\n",
    "s4 = s_4(b7, b8, Vtop, C4, D4)\n",
    "s5 = s_5(b9, b10, Vtop, C5, D5)\n",
    "s6 = s_6(b11, b12, Vtop, C6, D6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ddefine x, y firstly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "F1 = F_1(a1, a2, a3, a4, a7, Al1, Al2, Al3, s1, s2, s3, Vbot,x,y)\n",
    "F2 = F_2(a1, a5, a6, a4, a7, Au1, Au2, Au3, s4, s5, s6, Vtop,x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(Vbot,F1,'b')\n",
    "plt.plot(Vtop,F2,'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unloop..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "F1 = np.asarray(F1)\n",
    "F2 = np.asarray(F2)\n",
    "F4 = F2[0:47]\n",
    "F3 = F2[48:95]\n",
    "F5 = np.flip(F1)\n",
    "F6 = np.concatenate((F3,F5,F4),axis=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Vbot = np.linspace(-15,15,96)\n",
    "Vtop = np.linspace(-15,15,96)\n",
    "\n",
    "Fx = []\n",
    "Fy = []\n",
    "\n",
    "for k in range(1000):\n",
    "    a1 = np.random.uniform(-6,-4,2)\n",
    "    a2 = np.random.uniform(2,4,2)\n",
    "    a3 = np.random.uniform(11,13,2)\n",
    "    a4 = np.random.uniform(14,16,2)\n",
    "    a5 = np.random.uniform(1,3,2)\n",
    "    a6 = np.random.uniform(9,11,2)\n",
    "    a7 = np.random.uniform(0,1,2)\n",
    "    b1 = np.random.uniform(1, 1, 2)\n",
    "    b2 = np.random.uniform(4, 6, 2)\n",
    "    b3 = np.random.uniform(1, 1, 2)\n",
    "    b4 = np.random.uniform(4, 6, 2)\n",
    "    b5 = np.random.uniform(1, 1, 2)\n",
    "    b6 = np.random.uniform(4, 6, 2)\n",
    "    b7 = np.random.uniform(1, 1, 2)\n",
    "    b8 = np.random.uniform(4, 6, 2)\n",
    "    b9 = np.random.uniform(1, 1, 2)\n",
    "    b10 = np.random.uniform(4, 6, 2)\n",
    "    b11 = np.random.uniform(1, 1, 2)\n",
    "    b12 = np.random.uniform(4, 6, 2)\n",
    "    Al1= np.random.uniform(2,4,2)\n",
    "    Al2= np.random.uniform(-3,-1,2)\n",
    "    Al3= np.random.uniform(-7,-5,2)\n",
    "    Au1= np.random.uniform(-9,-7,2)\n",
    "    Au2= np.random.uniform(-5,-3,2)\n",
    "    Au3= np.random.uniform(-1,1,2)\n",
    "    C1 = np.random.uniform(-2,0,2)\n",
    "    C2 = np.random.uniform(-2,0,2)\n",
    "    C3 = np.random.uniform(-2,0,2)\n",
    "    C4 = np.random.uniform(5,7,2)\n",
    "    C5 = np.random.uniform(5,7,2)\n",
    "    C6 = np.random.uniform(5,7,2)\n",
    "    D1 = np.random.uniform(0,2,2)\n",
    "    D2 = np.random.uniform(0,2,2)\n",
    "    D3 = np.random.uniform(0,2,2)\n",
    "    D4 = np.random.uniform(0,2,2)\n",
    "    D5 = np.random.uniform(0,2,2)\n",
    "    D6 = np.random.uniform(0,2,2)\n",
    "    \n",
    "    x = np.random.randint(2)\n",
    "    y = np.random.randint(2)\n",
    "    m = np.random.randint(2)\n",
    "    n = np.random.randint(2)\n",
    "    s1 = s_1(b1[0], b2[0], Vbot, C1[0], D1[0])\n",
    "    s2 = s_2(b3[0], b4[0], Vbot, C2[0], D2[0])\n",
    "    s3 = s_3(b5[0], b6[0], Vbot, C3[0], D3[0])\n",
    "    s4 = s_4(b7[0], b8[0], Vtop, C4[0], D4[0])\n",
    "    s5 = s_5(b9[0], b10[0], Vtop, C5[0], D5[0])\n",
    "    s6 = s_6(b11[0], b12[0], Vtop, C6[0], D6[0])\n",
    "    \n",
    "    s11 = s_1(b1[1], b2[1], Vbot, C1[1], D1[1])\n",
    "    s21 = s_2(b3[1], b4[1], Vbot, C2[1], D2[1])\n",
    "    s31 = s_3(b5[1], b6[1], Vbot, C3[1], D3[1])\n",
    "    s41 = s_4(b7[1], b8[1], Vtop, C4[1], D4[1])\n",
    "    s51 = s_5(b9[1], b10[1], Vtop, C5[1], D5[1])\n",
    "    s61 = s_6(b11[1], b12[1], Vtop, C6[1], D6[1])\n",
    "    \n",
    "    F1 = F_1(a1[0], a2[0], a3[0], a4[0], a7[0], Al1[0], Al2[0], Al3[0], s1, s2, s3, Vbot,x,y)\n",
    "    F2 = F_2(a1[0], a5[0], a6[0], a4[0], a7[0], Au1[0], Au2[0], Au3[0], s4, s5, s6, Vtop,x,y)\n",
    "    \n",
    "    F11 = F_1(a1[1], a2[1], a3[1], a4[1], a7[1], Al1[1], Al2[1], Al3[1], s11, s21, s31, Vbot,m,n)\n",
    "    F21 = F_2(a1[1], a5[1], a6[1], a4[1], a7[1], Au1[1], Au2[1], Au3[1], s41, s51, s61, Vtop,m,n)\n",
    "    \n",
    "    \n",
    "    F1 = np.asarray(F1)\n",
    "    F2 = np.asarray(F2)\n",
    "    F4 = F2[0:48]\n",
    "    F3 = F2[48:96]\n",
    "    F5 = np.flip(F1)\n",
    "    Fx_ = np.concatenate((F3,F5,F4),axis=None)\n",
    "    Fx.append(Fx_)\n",
    "    \n",
    "    F11 = np.asarray(F11)\n",
    "    F21 = np.asarray(F21)\n",
    "    F41 = F21[0:48]\n",
    "    F31 = F21[48:96]\n",
    "    F51 = np.flip(F11)\n",
    "    Fy_ = np.concatenate((F31,F51,F41),axis = None)\n",
    "    Fy.append(Fy_)\n",
    "    \n",
    "    \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reshape_loop(F1,F2):\n",
    "    F11 = np.asarray(F1)\n",
    "    F21 = np.asarray(F2)\n",
    "    F41 = F21[0:48]\n",
    "    F31 = F21[48:96]\n",
    "    F51 = np.flip(F11)\n",
    "    Fy_ = np.concatenate((F31,F51,F41),axis = None)\n",
    "    return Fy_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1-D Convolutional Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Identity_Block(X, time_step, kernel_size, drop_out ):\n",
    "    \n",
    "    x = Conv1D(time_step, kernel_size, padding='same')(X)\n",
    "    x = LayerNormalization(axis=1)(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = tf.transpose(x, (0, 2, 1)) \n",
    "    x = Attention()([x,x])\n",
    "    x = tf.transpose(x, (0, 2, 1))\n",
    "    x = Dropout(drop_out)(x)\n",
    "    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Conv1D_Block(X, time_step, kernel_size, drop_out):\n",
    "    X_input = X\n",
    "    x = Conv1D(time_step, kernel_size, padding='same')(X)\n",
    "    x = LayerNormalization(axis=1)(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = tf.transpose(x, (0, 2, 1)) \n",
    "    x = Attention()([x,x])\n",
    "    x = tf.transpose(x, (0, 2, 1)) \n",
    "    \n",
    "    x = Conv1D(time_step, kernel_size, padding='same')(x)\n",
    "    x = LayerNormalization(axis=1)(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = tf.transpose(x, (0, 2, 1)) \n",
    "    x = Attention()([x,x])\n",
    "    x = tf.transpose(x, (0, 2, 1)) \n",
    "    \n",
    "    x = Conv1D(time_step, kernel_size, padding='same')(x)\n",
    "    x = LayerNormalization(axis=1)(x)\n",
    "    x = tf.transpose(x, (0, 2, 1)) \n",
    "    x = Attention()([x,x])\n",
    "    x = tf.transpose(x, (0, 2, 1))\n",
    "    x = Dropout(drop_out)(x)\n",
    "    \n",
    "    x = layers.add([X_input,x])\n",
    "    x = Activation('relu')(x)\n",
    "    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Conv1D_Pie(size = 12, time_step = 128, kernel_size = 3, lr = 2e-5, embedding = 8, \n",
    "                  n_step = 96, drop_out=0.2, l2_norm = 5e-7):\n",
    "    X_input = layers.Input(shape=(n_step,1))\n",
    "    X = X_input\n",
    "    Embedding_out = layers.Input(shape=(8,))\n",
    "    \n",
    "    x = Identity_Block(X, time_step, kernel_size, drop_out)\n",
    "    x = Conv1D_Block(x, time_step, kernel_size, drop_out)\n",
    "    x = Conv1D_Block(x, time_step, kernel_size, drop_out)\n",
    "    x = MaxPooling1D(2, padding='same')(x)\n",
    "    x = Identity_Block(x, time_step, kernel_size, drop_out)\n",
    "    x = Conv1D_Block(x, time_step, kernel_size, drop_out)\n",
    "    x = Conv1D_Block(x, time_step, kernel_size, drop_out)\n",
    "    x = MaxPooling1D(2, padding='same')(x)\n",
    "# x = Conv1D(128, 3, activation='relu', padding='same')(x)\n",
    "# encoded = MaxPooling1D(2, padding='same')(x)\n",
    "    x = tf.transpose(x, (0, 2, 1)) \n",
    "    encoded = Bidirectional(LSTM(size, return_sequences=False, dropout=drop_out))(x)\n",
    "# # at this point the representation is (4, 4, 8) i.e. 128-dimensional\n",
    "    embedding = Dense(embedding, activation='relu',activity_regularizer=l2(l2_norm))(encoded)\n",
    "    \n",
    "    repeat = RepeatVector(128)(embedding)\n",
    "    x = tf.transpose(repeat, (0, 2, 1)) \n",
    "    \n",
    "    x = Identity_Block(x, time_step, kernel_size, drop_out)\n",
    "    x = Conv1D_Block(x, time_step, kernel_size, drop_out)\n",
    "    x = Conv1D_Block(x, time_step, kernel_size, drop_out)\n",
    "    x = UpSampling1D(2)(x)\n",
    "    x = Identity_Block(x, time_step, kernel_size, drop_out)\n",
    "    x = Conv1D_Block(x, time_step, kernel_size, drop_out)\n",
    "    x = Conv1D_Block(x, time_step, kernel_size, drop_out)\n",
    "    x = UpSampling1D(2)(x)\n",
    "    x = Identity_Block(x, time_step, kernel_size, drop_out)\n",
    "    x = Conv1D_Block(x, time_step, kernel_size, drop_out)\n",
    "    x = Conv1D_Block(x, time_step, kernel_size, drop_out)\n",
    "    x = UpSampling1D(3)(x)\n",
    "    x = Identity_Block(x, time_step, kernel_size, drop_out)\n",
    "    x = Conv1D_Block(x, time_step, kernel_size, drop_out)\n",
    "    x = Conv1D_Block(x, time_step, kernel_size, drop_out)\n",
    "    decoded = Conv1D(1, 3, activation='linear', padding='same')(x)\n",
    "#x = UpSampling1D(2)(x)\n",
    "\n",
    "    model = Model(X_input, decoded,name = 'Convolutional_1D_with_Attention')\n",
    "    model.compile(Adam(lr), loss='mse')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python tensorflow_2_1",
   "language": "python",
   "name": "tf-2_1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
